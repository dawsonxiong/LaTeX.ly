{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e983d0",
   "metadata": {},
   "source": [
    "# **Training LaTeX.ly OCR using PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as f\n",
    "\n",
    "# PyTorch settings\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6a3da",
   "metadata": {},
   "source": [
    "### Task 1: Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.ImageFolder(\n",
    "    root='data/train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Load and display a sample image\n",
    "image_path = 'data/train/-/65_0.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "preprocessed_image = preprocess(image)\n",
    "\n",
    "# Adding batch dimension\n",
    "input_tensor = preprocessed_image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ec794",
   "metadata": {},
   "source": [
    "### Task 2: Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d737538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(dataset, batch_size, test_split=0.3, random_seed=42):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(test_split * dataset_size))\n",
    "    train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "    testset_size = len(test_indices)\n",
    "    indices = list(range(testset_size))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(0.5 * testset_size))\n",
    "    val_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating data samplers:\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "    # Creating data loaders:\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size, sampler=train_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size, sampler=test_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset, batch_size, sampler=val_sampler)\n",
    "\n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "# Randomly splitting training set into train, test, validation sets\n",
    "batch_size = 32\n",
    "train_loader, test_loader, val_loader = load_split(data, batch_size, test_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9141ac",
   "metadata": {},
   "source": [
    "### Task 3: Building a CNN and one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9726077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRNet(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(OCRNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(num_features, 81)  # Output has 81 classes instead of 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.conv1(x))\n",
    "        x = f.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "num_features = 32 * 64 * 64 # 64px x 64px x 32 channels\n",
    "model = OCRNet(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cd925",
   "metadata": {},
   "source": [
    "### Task 4: Set the Optimizer and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acaf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stochastic Gradient Descent (SGD) as the optimizer, and Cross Entropy Loss for loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a125458",
   "metadata": {},
   "source": [
    "### Task 5: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5cbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, num_epochs=20, print_every=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_count = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "            # Print loss for each step\n",
    "            if (i+1) % print_every == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Average Loss: {running_loss/running_count:.4f}\")\n",
    "                running_loss = 0.0\n",
    "                running_count = 0\n",
    "\n",
    "        # Print average loss after each epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\nEnd of Epoch {epoch+1}/{num_epochs}, Average Epoch Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "train(model, train_loader, optimizer, criterion, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af60d4",
   "metadata": {},
   "source": [
    "### Task 6: Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5450c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "validate(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d8a72",
   "metadata": {},
   "source": [
    "### Task 7: Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "test(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cff93",
   "metadata": {},
   "source": [
    "### Task 8: Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/LaTeXly_v5.pth')\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load('model/LaTeXly_v5.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c5239",
   "metadata": {},
   "source": [
    "### Task 9: Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c917781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding symbols for each class\n",
    "classes = ['!', '(', ')', '+', ',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '\\\\Delta', 'a', '\\\\alpha', \n",
    "    'b', '\\\\beta', 'c', 'd', '\\\\div', 'e', '\\\\exists', 'f', '\\\\forall', '/', 'g', '\\\\geq', '\\\\gt', 'h',\n",
    "    'i', '\\\\in', '\\\\infty', '\\\\int', 'j', 'k', '\\\\lambda', '\\\\leq', '\\\\lt', 'm', '\\\\mu', 'n', '\\\\neq', 'p', '\\\\pi',\n",
    "    '\\\\pm', 'q', 'r', '\\\\rightarrow', 's', '\\\\sigma', '\\\\sum', 't', '\\\\theta', '\\\\times', 'u', 'A', 'B', 'C',\n",
    "    'E', 'F', 'G', 'I', 'N', 'P', 'R', 'S', 'T', 'X', 'v', '|', 'w', 'x', 'y', 'z', '\\\\{', '\\\\}']\n",
    "\n",
    "def predict(model, image_path, transform):\n",
    "    image = Image.open(image_path).convert('RGB')  # Convert to RGB colour type\n",
    "    image = transform(image).unsqueeze(0)\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probabilities = f.softmax(output, dim=1)\n",
    "        predicted_prob, predicted_idx = torch.max(probabilities, 1)\n",
    "        predicted_class = classes[predicted_idx]\n",
    "        confidence = predicted_prob.item() * 100  # convert to percentage\n",
    "\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.title(f'Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return f'Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%'\n",
    "\n",
    "image_path = 'data/train/lt/1.png'\n",
    "\n",
    "# Call prediction function\n",
    "predict(model, image_path, preprocess)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
